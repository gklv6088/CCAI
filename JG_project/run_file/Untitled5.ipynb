{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import struct\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\"\n",
    "import numpy as np\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Input, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.layers import UpSampling2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers.merge import add, concatenate\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib.colors import rgb_to_hsv, hsv_to_rgb\n",
    "import cv2\n",
    "\n",
    "from keras.layers import Conv2D, Add, ZeroPadding2D, UpSampling2D, Concatenate, MaxPooling2D\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from keras.models import Model, load_model\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from yolo3.utils import compose\n",
    "\n",
    "from yolo3.model import yolo_eval, make_model\n",
    "\n",
    "\n",
    "from keras.regularizers import l2\n",
    "\n",
    "\n",
    "# def _conv_block(inp, convs, skip=True):\n",
    "#     x = inp\n",
    "#     count = 0\n",
    "#     for conv in convs:\n",
    "#         if count == (len(convs) - 2) and skip:\n",
    "#             skip_connection = x\n",
    "#         count += 1\n",
    "#         if conv['stride'] > 1: x = ZeroPadding2D(((1,0),(1,0)))(x) # peculiar padding as darknet prefer left and top\n",
    "#         x = Conv2D(conv['filter'],\n",
    "#                    conv['kernel'],\n",
    "#                    strides=conv['stride'],           \n",
    "#                    padding='valid' \n",
    "#                    if conv['stride'] > 1 else 'same',\n",
    "#                    name='conv_' + str(conv['layer_idx']),\n",
    "#                    use_bias=False if conv['bnorm'] else True)(x)\n",
    "#         if conv['bnorm']: x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)\n",
    "#         if conv['leaky']: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\n",
    "#     return add([skip_connection, x]) if skip else x\n",
    "\n",
    "# def make_yolov3_model(num_of_classes, num_of_anchors):\n",
    "#     input_image = Input(shape=(None, None, 3))\n",
    "\n",
    "#     res = (num_of_classes+5)*num_of_anchors\n",
    "       \n",
    "#     x = _conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\n",
    "#                                   {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\n",
    "#                                   {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\n",
    "#                                   {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\n",
    "    \n",
    "#     x = _conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\n",
    "#                        {'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\n",
    "#                        {'filter': 64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7},\n",
    "#                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 8}])\n",
    "    \n",
    "\n",
    "#     x = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 10},\n",
    "#                    {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 11},\n",
    "#                    {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 12}])\n",
    "    \n",
    "#     skip_2 = x\n",
    "    \n",
    "#     x = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 14},\n",
    "#                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 15},\n",
    "#                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16},\n",
    "#                        {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17}])\n",
    "\n",
    "#     skip_1 = x\n",
    "#     x = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 19},\n",
    "#                        {'filter': 512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 20},\n",
    "#                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 21}])\n",
    "    \n",
    "#     yolo_24 = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 23},\n",
    "#                               {'filter': res, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 24}], skip=False)\n",
    "\n",
    "#     x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 25}], skip=False)\n",
    "#     x = UpSampling2D(2)(x)\n",
    "    \n",
    "#     print(x)\n",
    "#     print(skip_1)\n",
    "#     x = concatenate([x, skip_1])\n",
    "#     x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 26},\n",
    "#                         {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 27},\n",
    "#                         {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 28}], skip=False)\n",
    "\n",
    "#     yolo_33 = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 29},\n",
    "#                               {'filter': res, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 30}], skip=False)\n",
    "#     # Layer 95 => 98\n",
    "#     x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 31}], skip=False)\n",
    "#     x = UpSampling2D(2)(x)\n",
    "    \n",
    "#     print(x)\n",
    "#     print(skip_2)\n",
    "#     x = concatenate([x, skip_2])\n",
    "    \n",
    "#     # Layer 99 => 106\n",
    "#     yolo_43 = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 32},\n",
    "#                                {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 33},\n",
    "#                                {'filter': res, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 34}], skip=False)\n",
    "#     model = Model(input_image, [yolo_24, yolo_33, yolo_43]) \n",
    "#     return model\n",
    "\n",
    "# def make_model(num_of_classes, num_of_anchors):\n",
    "#     input_image = Input(shape=(None, None, 3))\n",
    "    \n",
    "#     x = Conv2D(16,(3,1), padding = 'same')(input_image) # 416 x 416 x 16\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = LeakyReLU(alpha=0.1)(x)\n",
    "    \n",
    "#     x = Conv2D(32,(3,1), padding = 'same')(x) # 208 x 208 x 32\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = LeakyReLU(alpha=0.1)(x)\n",
    "    \n",
    "#     x = MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same')(x)\n",
    "    \n",
    "#     x = Conv2D(32,(3,1), padding = 'same')(x) # 208 x 208 x 32\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = LeakyReLU(alpha=0.1)(x)\n",
    "    \n",
    "#     x = Conv2D(64,(3,1), padding = 'same')(x) # 104 x 104 x64\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = LeakyReLU(alpha=0.1)(x)\n",
    "    \n",
    "#     x = MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same')(x)\n",
    "    \n",
    "#     x = Conv2D(64,(3,1), padding = 'same')(x) # 104 x 104 x64\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = LeakyReLU(alpha=0.1)(x)\n",
    "    \n",
    "#     x = Conv2D(128,(3,1), padding = 'same')(x) # 52 x 52 x128\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = LeakyReLU(alpha=0.1)(x)\n",
    "    \n",
    "#     x = MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same')(x)\n",
    "    \n",
    "#     x = Conv2D(256,(3,1), padding = 'same')(x) # 26 x 26 x 256    \n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = LeakyReLU(alpha=0.1)(x)\n",
    "    \n",
    "#     x = Conv2D(128,(3,1), padding = 'same')(x) # 52 x 52 x128\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = LeakyReLU(alpha=0.1)(x)\n",
    "    \n",
    "#     x = MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same')(x)\n",
    "    \n",
    "#     x = Conv2D(128,(3,1), padding = 'same')(x) # 52 x 52 x128\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = LeakyReLU(alpha=0.1)(x)\n",
    "    \n",
    "#     x = Conv2D(256,(3,1), padding = 'same')(x) # 26 x 26 x 256    \n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = LeakyReLU(alpha=0.1)(x)\n",
    "        \n",
    "    \n",
    "#     x1 = x # 26 x 26 x 256  \n",
    "    \n",
    "#     x = MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same')(x)\n",
    "    \n",
    "#     x = Conv2D(512,(3,1), padding = 'same')(x) # 13 x 13 x 512\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = LeakyReLU(alpha=0.1)(x)    \n",
    "\n",
    "#     x = MaxPooling2D(pool_size=(2,2), strides=(1,1), padding='same')(x)\n",
    "    \n",
    "#     x = Conv2D(1024,(3,1), padding = 'same')(x) # 13 x 13 x 1024\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = LeakyReLU(alpha=0.1)(x)\n",
    "#     x = Conv2D(256,(1,1),padding = 'same')(x) # 13 x 13 x 512\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = LeakyReLU(alpha=0.1)(x)\n",
    "    \n",
    "    \n",
    "#     yolo_1 = Conv2D(512,(3,1),padding = 'same')(x) # 13 x 13 x 1024\n",
    "#     yolo_1 = BatchNormalization()(yolo_1)\n",
    "#     yolo_1 = LeakyReLU(alpha=0.1)(yolo_1)\n",
    "#     yolo_1 = Conv2D((num_of_anchors)*(5+num_of_classes),(1,1))(yolo_1) # 13 x 13 x s\n",
    "\n",
    "    \n",
    "#     x = Conv2D(128,(1,1))(x) # 13 x 13 x 128  \n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = LeakyReLU(alpha=0.1)(x)\n",
    "#     x = UpSampling2D(2)(x) # 26 x26 x 128\n",
    "    \n",
    "#     x2 = x\n",
    "#     x = concatenate([x1,x2]) # 26 x 26 x 128\n",
    "\n",
    "    \n",
    "#     yolo_2 = Conv2D(256,(3,1),padding = 'same')(x) # 13 x 13 x 256\n",
    "#     yolo_2 = BatchNormalization()(yolo_2)\n",
    "#     yolo_2 = LeakyReLU(alpha=0.1)(yolo_2)\n",
    "#     yolo_2 = Conv2D((num_of_anchors)*(5+num_of_classes),(1,1))(yolo_2) # 13 x 13 x s    \n",
    "    \n",
    "#     model = Model(input_image, [yolo_1, yolo_2]) \n",
    "# #     model.summary()\n",
    "#     return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(args, anchors, num_classes, ignore_thresh=.5, print_loss=False):\n",
    "\n",
    "    num_layers = len(anchors)//3 # default setting\n",
    "    yolo_outputs = args[:num_layers]\n",
    "    y_true = args[num_layers:]\n",
    "    anchor_mask = [[6,7,8], [3,4,5], [0,1,2]] if num_layers==3 else [[3,4,5], [1,2,3]]\n",
    "    input_shape = K.cast(K.shape(yolo_outputs[0])[1:3] * 32, K.dtype(y_true[0]))\n",
    "    grid_shapes = [K.cast(K.shape(yolo_outputs[l])[1:3], K.dtype(y_true[0])) for l in range(num_layers)]\n",
    "    loss = 0\n",
    "    m = K.shape(yolo_outputs[0])[0] # batch size, tensor\n",
    "    mf = K.cast(m, K.dtype(yolo_outputs[0]))\n",
    "\n",
    "    for l in range(num_layers):\n",
    "        object_mask = y_true[l][..., 4:5]\n",
    "        true_class_probs = y_true[l][..., 5:]\n",
    "\n",
    "        grid, raw_pred, pred_xy, pred_wh = model_head(yolo_outputs[l],\n",
    "             anchors[anchor_mask[l]], num_classes, input_shape, calc_loss=True)\n",
    "        pred_box = K.concatenate([pred_xy, pred_wh])\n",
    "\n",
    "        # Darknet raw box to calculate loss.\n",
    "        raw_true_xy = y_true[l][..., :2]*grid_shapes[l][::-1] - grid\n",
    "        raw_true_wh = K.log(y_true[l][..., 2:4] / anchors[anchor_mask[l]] * input_shape[::-1])\n",
    "        raw_true_wh = K.switch(object_mask, raw_true_wh, K.zeros_like(raw_true_wh)) # avoid log(0)=-inf\n",
    "        box_loss_scale = 2 - y_true[l][...,2:3]*y_true[l][...,3:4]\n",
    "\n",
    "        # Find ignore mask, iterate over each of batch.\n",
    "        ignore_mask = tf.TensorArray(K.dtype(y_true[0]), size=1, dynamic_size=True)\n",
    "        object_mask_bool = K.cast(object_mask, 'bool')\n",
    "        def loop_body(b, ignore_mask):\n",
    "            true_box = tf.boolean_mask(y_true[l][b,...,0:4], object_mask_bool[b,...,0])\n",
    "            iou = box_iou(pred_box[b], true_box)\n",
    "            best_iou = K.max(iou, axis=-1)\n",
    "            ignore_mask = ignore_mask.write(b, K.cast(best_iou<ignore_thresh, K.dtype(true_box)))\n",
    "            return b+1, ignore_mask\n",
    "        _, ignore_mask = K.control_flow_ops.while_loop(lambda b,*args: b<m, loop_body, [0, ignore_mask])\n",
    "        ignore_mask = ignore_mask.stack()\n",
    "        ignore_mask = K.expand_dims(ignore_mask, -1)\n",
    "\n",
    "        # K.binary_crossentropy is helpful to avoid exp overflow.\n",
    "        xy_loss = object_mask * box_loss_scale * K.binary_crossentropy(raw_true_xy, raw_pred[...,0:2], from_logits=True)\n",
    "        wh_loss = object_mask * box_loss_scale * 0.5 * K.square(raw_true_wh-raw_pred[...,2:4])\n",
    "        confidence_loss = object_mask * K.binary_crossentropy(object_mask, raw_pred[...,4:5], from_logits=True)+ \\\n",
    "            (1-object_mask) * K.binary_crossentropy(object_mask, raw_pred[...,4:5], from_logits=True) * ignore_mask\n",
    "        class_loss = object_mask * K.binary_crossentropy(true_class_probs, raw_pred[...,5:], from_logits=True)\n",
    "\n",
    "        xy_loss = K.sum(xy_loss) / mf\n",
    "        wh_loss = K.sum(wh_loss) / mf\n",
    "        confidence_loss = K.sum(confidence_loss) / mf\n",
    "        class_loss = K.sum(class_loss) / mf\n",
    "        loss += xy_loss + wh_loss + confidence_loss + class_loss\n",
    "        if print_loss:\n",
    "            loss = tf.Print(loss, [loss, xy_loss, wh_loss, confidence_loss, class_loss, K.sum(ignore_mask)], message='loss: ')\n",
    "    return loss\n",
    "\n",
    "def model_head(feats, anchors, num_classes, input_shape, calc_loss=False):\n",
    "    \"\"\"Convert final layer features to bounding box parameters.\"\"\"\n",
    "    num_anchors = len(anchors)\n",
    "    # Reshape to batch, height, width, num_anchors, box_params.\n",
    "    anchors_tensor = K.reshape(K.constant(anchors), [1, 1, 1, num_anchors, 2])\n",
    "\n",
    "    grid_shape = K.shape(feats)[1:3] # height, width\n",
    "    grid_y = K.tile(K.reshape(K.arange(0, stop=grid_shape[0]), [-1, 1, 1, 1]),\n",
    "        [1, grid_shape[1], 1, 1])\n",
    "    grid_x = K.tile(K.reshape(K.arange(0, stop=grid_shape[1]), [1, -1, 1, 1]),\n",
    "        [grid_shape[0], 1, 1, 1])\n",
    "    grid = K.concatenate([grid_x, grid_y])\n",
    "    grid = K.cast(grid, K.dtype(feats))\n",
    "\n",
    "    feats = K.reshape(\n",
    "        feats, [-1, grid_shape[0], grid_shape[1], num_anchors, num_classes + 5])\n",
    "\n",
    "    # Adjust preditions to each spatial grid point and anchor size.\n",
    "    box_xy = (K.sigmoid(feats[..., :2]) + grid) / K.cast(grid_shape[::-1], K.dtype(feats))\n",
    "    box_wh = K.exp(feats[..., 2:4]) * anchors_tensor / K.cast(input_shape[::-1], K.dtype(feats))\n",
    "    box_confidence = K.sigmoid(feats[..., 4:5])\n",
    "    box_class_probs = K.sigmoid(feats[..., 5:])\n",
    "\n",
    "    if calc_loss == True:\n",
    "        return grid, feats, box_xy, box_wh\n",
    "    return box_xy, box_wh, box_confidence, box_class_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(classes_path):\n",
    "    '''loads the classes'''\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names\n",
    "\n",
    "def get_anchors(anchors_path):\n",
    "    '''loads the anchors from a file'''\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "    anchors = [float(x) for x in anchors.split(',')]\n",
    "    return np.array(anchors).reshape(-1, 2)\n",
    "\n",
    "def data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    '''data generator for fit_generator'''\n",
    "    n = len(annotation_lines)\n",
    "    i = 0\n",
    "    while True:\n",
    "        image_data = []\n",
    "        box_data = []\n",
    "        for b in range(batch_size):\n",
    "            if i==0:\n",
    "                np.random.shuffle(annotation_lines)\n",
    "            image, box = get_random_data(annotation_lines[i], input_shape, random=True)\n",
    "            image_data.append(image)\n",
    "            box_data.append(box)\n",
    "            i = (i+1) % n\n",
    "        image_data = np.array(image_data)\n",
    "        box_data = np.array(box_data)\n",
    "        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
    "        yield [image_data, *y_true], np.zeros(batch_size)\n",
    "\n",
    "def preprocess_true_boxes(true_boxes, input_shape, anchors, num_classes):\n",
    "    assert (true_boxes[..., 4]<num_classes).all(), 'class id must be less than num_classes'\n",
    "    num_layers = len(anchors)//3 # default setting\n",
    "    anchor_mask = [[6,7,8], [3,4,5], [0,1,2]] if num_layers==3 else [[3,4,5], [1,2,3]]\n",
    "\n",
    "    true_boxes = np.array(true_boxes, dtype='float32')\n",
    "    input_shape = np.array(input_shape, dtype='int32')\n",
    "    boxes_xy = (true_boxes[..., 0:2] + true_boxes[..., 2:4]) // 2\n",
    "    boxes_wh = true_boxes[..., 2:4] - true_boxes[..., 0:2]\n",
    "    true_boxes[..., 0:2] = boxes_xy/input_shape[::-1]\n",
    "    true_boxes[..., 2:4] = boxes_wh/input_shape[::-1]\n",
    "\n",
    "    m = true_boxes.shape[0]\n",
    "    grid_shapes = [input_shape//{0:32, 1:16, 2:8}[l] for l in range(num_layers)]\n",
    "    y_true = [np.zeros((m,grid_shapes[l][0],grid_shapes[l][1],len(anchor_mask[l]),5+num_classes),\n",
    "        dtype='float32') for l in range(num_layers)]\n",
    "\n",
    "    # Expand dim to apply broadcasting.\n",
    "    anchors = np.expand_dims(anchors, 0)\n",
    "    anchor_maxes = anchors / 2.\n",
    "    anchor_mins = -anchor_maxes\n",
    "    valid_mask = boxes_wh[..., 0]>0\n",
    "\n",
    "    for b in range(m):\n",
    "        # Discard zero rows.\n",
    "        wh = boxes_wh[b, valid_mask[b]]\n",
    "        if len(wh)==0: continue\n",
    "        # Expand dim to apply broadcasting.\n",
    "        wh = np.expand_dims(wh, -2)\n",
    "        box_maxes = wh / 2.\n",
    "        box_mins = -box_maxes\n",
    "\n",
    "        intersect_mins = np.maximum(box_mins, anchor_mins)\n",
    "        intersect_maxes = np.minimum(box_maxes, anchor_maxes)\n",
    "        intersect_wh = np.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "        intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "        box_area = wh[..., 0] * wh[..., 1]\n",
    "        anchor_area = anchors[..., 0] * anchors[..., 1]\n",
    "        iou = intersect_area / (box_area + anchor_area - intersect_area)\n",
    "\n",
    "        # Find best anchor for each true box\n",
    "        best_anchor = np.argmax(iou, axis=-1)\n",
    "\n",
    "        for t, n in enumerate(best_anchor):\n",
    "            for l in range(num_layers):\n",
    "                if n in anchor_mask[l]:\n",
    "                    i = np.floor(true_boxes[b,t,0]*grid_shapes[l][1]).astype('int32')\n",
    "                    j = np.floor(true_boxes[b,t,1]*grid_shapes[l][0]).astype('int32')\n",
    "                    k = anchor_mask[l].index(n)\n",
    "                    c = true_boxes[b,t, 4].astype('int32')\n",
    "                    y_true[l][b, j, i, k, 0:4] = true_boxes[b,t, 0:4]\n",
    "                    y_true[l][b, j, i, k, 4] = 1\n",
    "                    y_true[l][b, j, i, k, 5+c] = 1\n",
    "\n",
    "    return y_true\n",
    "\n",
    "def data_generator_wrapper(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    n = len(annotation_lines)\n",
    "    if n==0 or batch_size<=0: return None\n",
    "    return data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes)\n",
    "\n",
    "def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n",
    "    new_w, new_h = net_w, net_h\n",
    "    for i in range(len(boxes)):\n",
    "        x_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
    "        y_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
    "        boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
    "        boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
    "        boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
    "        boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n",
    "\n",
    "def get_random_data(annotation_line, input_shape, random=True, max_boxes=20, jitter=.3, hue=.1, sat=1.5, val=1.5, proc_img=True):\n",
    "    '''random preprocessing for real-time data augmentation'''\n",
    "    line = annotation_line.split()\n",
    "    image = Image.open(line[0])\n",
    "    iw, ih = image.size\n",
    "    h, w = input_shape\n",
    "    box = np.array([np.array(list(map(int,box.split(',')))) for box in line[1:]])\n",
    "\n",
    "    if not random:\n",
    "        # resize image\n",
    "        scale = min(w/iw, h/ih)\n",
    "        nw = int(iw*scale)\n",
    "        nh = int(ih*scale)\n",
    "        dx = (w-nw)//2\n",
    "        dy = (h-nh)//2\n",
    "        image_data=0\n",
    "        if proc_img:\n",
    "            image = image.resize((nw,nh), Image.BICUBIC)\n",
    "            new_image = Image.new('RGB', (w,h), (128,128,128))\n",
    "            new_image.paste(image, (dx, dy))\n",
    "            image_data = np.array(new_image)/255.\n",
    "\n",
    "        # correct boxes\n",
    "        box_data = np.zeros((max_boxes,5))\n",
    "        if len(box)>0:\n",
    "            np.random.shuffle(box)\n",
    "            if len(box)>max_boxes: box = box[:max_boxes]\n",
    "            box[:, [0,2]] = box[:, [0,2]]*scale + dx\n",
    "            box[:, [1,3]] = box[:, [1,3]]*scale + dy\n",
    "            box_data[:len(box)] = box\n",
    "\n",
    "        return image_data, box_data\n",
    "\n",
    "    # resize image\n",
    "    new_ar = w/h * rand(1-jitter,1+jitter)/rand(1-jitter,1+jitter)\n",
    "    scale = rand(.25, 2)\n",
    "    if new_ar < 1:\n",
    "        nh = int(scale*h)\n",
    "        nw = int(nh*new_ar)\n",
    "    else:\n",
    "        nw = int(scale*w)\n",
    "        nh = int(nw/new_ar)\n",
    "    image = image.resize((nw,nh), Image.BICUBIC)\n",
    "\n",
    "    # place image\n",
    "    dx = int(rand(0, w-nw))\n",
    "    dy = int(rand(0, h-nh))\n",
    "    new_image = Image.new('RGB', (w,h), (128,128,128))\n",
    "    new_image.paste(image, (dx, dy))\n",
    "    image = new_image\n",
    "\n",
    "    # flip image or not\n",
    "    flip = rand()<.5\n",
    "    if flip: image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "    # distort image\n",
    "    hue = rand(-hue, hue)\n",
    "    sat = rand(1, sat) if rand()<.5 else 1/rand(1, sat)\n",
    "    val = rand(1, val) if rand()<.5 else 1/rand(1, val)\n",
    "    x = rgb_to_hsv(np.array(image)/255.)\n",
    "    x[..., 0] += hue\n",
    "    x[..., 0][x[..., 0]>1] -= 1\n",
    "    x[..., 0][x[..., 0]<0] += 1\n",
    "    x[..., 1] *= sat\n",
    "    x[..., 2] *= val\n",
    "    x[x>1] = 1\n",
    "    x[x<0] = 0\n",
    "    image_data = hsv_to_rgb(x) # numpy array, 0 to 1\n",
    "\n",
    "    # correct boxes\n",
    "    box_data = np.zeros((max_boxes,5))\n",
    "    if len(box)>0:\n",
    "        np.random.shuffle(box)\n",
    "        box[:, [0,2]] = box[:, [0,2]]*nw/iw + dx\n",
    "        box[:, [1,3]] = box[:, [1,3]]*nh/ih + dy\n",
    "        if flip: box[:, [0,2]] = w - box[:, [2,0]]\n",
    "        box[:, 0:2][box[:, 0:2]<0] = 0\n",
    "        box[:, 2][box[:, 2]>w] = w\n",
    "        box[:, 3][box[:, 3]>h] = h\n",
    "        box_w = box[:, 2] - box[:, 0]\n",
    "        box_h = box[:, 3] - box[:, 1]\n",
    "        box = box[np.logical_and(box_w>1, box_h>1)] # discard invalid box\n",
    "        if len(box)>max_boxes: box = box[:max_boxes]\n",
    "        box_data[:len(box)] = box\n",
    "\n",
    "    return image_data, box_data\n",
    "\n",
    "        \n",
    "def _interval_overlap(interval_a, interval_b):\n",
    "    x1, x2 = interval_a\n",
    "    x3, x4 = interval_b\n",
    "    if x3 < x1:\n",
    "        if x4 < x1:\n",
    "            return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x1\n",
    "    else:\n",
    "        if x2 < x3:\n",
    "            return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x3\n",
    "\n",
    "def rand(a=0, b=1):\n",
    "    return np.random.rand()*(b-a) + a\n",
    "\n",
    "def box_iou(b1, b2):\n",
    "    '''Return iou tensor\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    b1: tensor, shape=(i1,...,iN, 4), xywh\n",
    "    b2: tensor, shape=(j, 4), xywh\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    iou: tensor, shape=(i1,...,iN, j)\n",
    "\n",
    "    '''\n",
    "\n",
    "    # Expand dim to apply broadcasting.\n",
    "    b1 = K.expand_dims(b1, -2)\n",
    "    b1_xy = b1[..., :2]\n",
    "    b1_wh = b1[..., 2:4]\n",
    "    b1_wh_half = b1_wh/2.\n",
    "    b1_mins = b1_xy - b1_wh_half\n",
    "    b1_maxes = b1_xy + b1_wh_half\n",
    "\n",
    "    # Expand dim to apply broadcasting.\n",
    "    b2 = K.expand_dims(b2, 0)\n",
    "    b2_xy = b2[..., :2]\n",
    "    b2_wh = b2[..., 2:4]\n",
    "    b2_wh_half = b2_wh/2.\n",
    "    b2_mins = b2_xy - b2_wh_half\n",
    "    b2_maxes = b2_xy + b2_wh_half\n",
    "\n",
    "    intersect_mins = K.maximum(b1_mins, b2_mins)\n",
    "    intersect_maxes = K.minimum(b1_maxes, b2_maxes)\n",
    "    intersect_wh = K.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    b1_area = b1_wh[..., 0] * b1_wh[..., 1]\n",
    "    b2_area = b2_wh[..., 0] * b2_wh[..., 1]\n",
    "    iou = intersect_area / (b1_area + b2_area - intersect_area)\n",
    "\n",
    "    return iou\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"up_sampling2d_3/ResizeNearestNeighbor:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "Tensor(\"add_9/add:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "Tensor(\"up_sampling2d_4/ResizeNearestNeighbor:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "Tensor(\"add_8/add:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "Create custom model with 9 anchors and 3 classes.\n"
     ]
    }
   ],
   "source": [
    "annotation_path = '3_CLASS_test.txt'\n",
    "log_dir = 'logs/000/'\n",
    "classes_path = '3_CLASS_test_classes.txt'\n",
    "anchors_path = 'model_data/yolo_anchors.txt'\n",
    "class_names = get_classes(classes_path)\n",
    "num_classes = len(class_names)\n",
    "anchors = get_anchors(anchors_path)\n",
    "\n",
    "input_shape = (416,416) # multiple of 32, hw\n",
    "\n",
    "\n",
    "image_input = Input(shape=(None, None, 3))\n",
    "\n",
    "h, w = input_shape\n",
    "num_anchors = len(anchors)\n",
    "\n",
    "y_true = [Input(shape=(h//{0:32, 1:16, 2:8}[l], w//{0:32, 1:16, 2:8}[l], \\\n",
    "    num_anchors//3, num_classes+5)) for l in range(3)]\n",
    "\n",
    "model_body = make_model(num_anchors//3, num_classes)\n",
    "print('Create custom model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
    "model_body.load_weights(\"./customv3_500_weights.h5\")\n",
    "\n",
    "model_loss = Lambda(custom_loss, output_shape=(1,), name='loss',\n",
    "    arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})(\n",
    "    [*model_body.output, *y_true])\n",
    "model = Model([model_body.input, *y_true], model_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.0001), loss={'loss': lambda y_true, y_pred: y_pred})\n",
    "logging = TensorBoard(log_dir=log_dir)\n",
    "checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5909\n",
      "63091\n"
     ]
    }
   ],
   "source": [
    "# coco dataset\n",
    "coco_annotation_path =\"./coco_data/train.txt\"\n",
    "coco_annotation_val_path = \"./coco_data/val.txt\"\n",
    "class_list = \"./coco_data/coco_classes.txt\"\n",
    "\n",
    "with open(coco_annotation_path) as f:\n",
    "    trains = f.readlines()\n",
    "\n",
    "with open(coco_annotation_val_path) as f:\n",
    "    valids = f.readlines()\n",
    "\n",
    "\n",
    "class_names = get_classes(class_list)\n",
    "\n",
    "val_split = 0.1\n",
    "with open(annotation_path) as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "    \n",
    "np.random.shuffle(lines)\n",
    "\n",
    "num_val1 = int(len(lines)*val_split)\n",
    "num_train1= len(lines) - num_val1\n",
    "\n",
    "trains += lines[:num_train1]\n",
    "valids += lines[num_train1:]\n",
    "\n",
    "\n",
    "num_train = len(trains)\n",
    "num_val = len(valids)\n",
    "\n",
    "\n",
    "\n",
    "print(num_val)\n",
    "print(num_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 16\n",
    "# print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "# model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
    "#         steps_per_epoch=max(1, num_train//batch_size),\n",
    "#         validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
    "#         validation_steps=max(1, num_val//batch_size),\n",
    "#         epochs=5,\n",
    "#         callbacks=[logging, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 63091 samples, val on 5909 samples, with batch size 16.\n",
      "Epoch 1/15\n",
      "3943/3943 [==============================] - 4568s 1s/step - loss: 12.8472 - val_loss: 12.4755\n",
      "Epoch 2/15\n",
      "3943/3943 [==============================] - 4295s 1s/step - loss: 12.8052 - val_loss: 12.5744\n",
      "Epoch 3/15\n",
      "3943/3943 [==============================] - 4362s 1s/step - loss: 12.7806 - val_loss: 12.4157\n",
      "Epoch 4/15\n",
      "3943/3943 [==============================] - 4357s 1s/step - loss: 12.7486 - val_loss: 12.5112\n",
      "Epoch 5/15\n",
      "3943/3943 [==============================] - 4343s 1s/step - loss: 12.7753 - val_loss: 12.4801\n",
      "Epoch 6/15\n",
      "3943/3943 [==============================] - 4310s 1s/step - loss: 12.7539 - val_loss: 12.4134\n",
      "Epoch 7/15\n",
      "3943/3943 [==============================] - 4269s 1s/step - loss: 12.7443 - val_loss: 12.5228\n",
      "Epoch 8/15\n",
      "3943/3943 [==============================] - 4263s 1s/step - loss: 12.6947 - val_loss: 12.3414\n",
      "Epoch 9/15\n",
      "3943/3943 [==============================] - 4271s 1s/step - loss: 12.6682 - val_loss: 12.4917\n",
      "Epoch 10/15\n",
      "3943/3943 [==============================] - 4299s 1s/step - loss: 12.6851 - val_loss: 12.3480\n",
      "Epoch 11/15\n",
      "3943/3943 [==============================] - 4280s 1s/step - loss: 12.6158 - val_loss: 12.2305\n",
      "Epoch 12/15\n",
      "3943/3943 [==============================] - 4259s 1s/step - loss: 12.6193 - val_loss: 12.3962\n",
      "Epoch 13/15\n",
      "3943/3943 [==============================] - 4267s 1s/step - loss: 12.6304 - val_loss: 12.4723\n",
      "Epoch 14/15\n",
      "3943/3943 [==============================] - 4255s 1s/step - loss: 12.5807 - val_loss: 12.4944\n",
      "Epoch 15/15\n",
      "3943/3943 [==============================] - 4250s 1s/step - loss: 12.5839 - val_loss: 12.4027\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "model.fit_generator(data_generator_wrapper(trains, batch_size, input_shape, anchors, num_classes),\n",
    "        steps_per_epoch=max(1, num_train//batch_size),\n",
    "        validation_data=data_generator_wrapper(valids, batch_size, input_shape, anchors, num_classes),\n",
    "        validation_steps=max(1, num_val//batch_size),\n",
    "        epochs=15,\n",
    "        callbacks=[logging, checkpoint])\n",
    "\n",
    "model.save_weights(\"customv3_520_weights.h5\")\n",
    "model.save(\"customv3_520_models.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data 늘려가면서 epoch = 20 고정으로 학습 진행 \n",
    "# loss 가 떨어지지 않는 지점에서 ignore threshold 를 낮춰가면서 반복하여 최적의학습 파라미터 찾아감\n",
    "model.save_weights(\"customv3_550_weights.h5\")\n",
    "model.save(\"customv3_550_models.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# load yolov3 model and perform object detection\n",
    "# based on https://github.com/experiencor/keras-yolo3\n",
    "import numpy as np\n",
    "from numpy import expand_dims\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle\n",
    " \n",
    "class BoundBox:\n",
    "\tdef __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
    "\t\tself.xmin = xmin\n",
    "\t\tself.ymin = ymin\n",
    "\t\tself.xmax = xmax\n",
    "\t\tself.ymax = ymax\n",
    "\t\tself.objness = objness\n",
    "\t\tself.classes = classes\n",
    "\t\tself.label = -1\n",
    "\t\tself.score = -1\n",
    " \n",
    "\tdef get_label(self):\n",
    "\t\tif self.label == -1:\n",
    "\t\t\tself.label = np.argmax(self.classes)\n",
    " \n",
    "\t\treturn self.label\n",
    " \n",
    "\tdef get_score(self):\n",
    "\t\tif self.score == -1:\n",
    "\t\t\tself.score = self.classes[self.get_label()]\n",
    " \n",
    "\t\treturn self.score\n",
    " \n",
    "def _sigmoid(x):\n",
    "\treturn 1. / (1. + np.exp(-x))\n",
    " \n",
    "def decode_netout(netout, anchors, obj_thresh, net_h, net_w):\n",
    "\tgrid_h, grid_w = netout.shape[:2]\n",
    "\tnb_box = 3\n",
    "\tnetout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
    "\tnb_class = netout.shape[-1] - 5\n",
    "\tboxes = []\n",
    "\tnetout[..., :2]  = _sigmoid(netout[..., :2])\n",
    "\tnetout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
    "\tnetout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
    "\tnetout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
    " \n",
    "\tfor i in range(grid_h*grid_w):\n",
    "\t\trow = i / grid_w\n",
    "\t\tcol = i % grid_w\n",
    "\t\tfor b in range(nb_box):\n",
    "\t\t\t# 4th element is objectness score\n",
    "\t\t\tobjectness = netout[int(row)][int(col)][b][4]\n",
    "\t\t\tif(objectness.all() <= obj_thresh): continue\n",
    "\t\t\t# first 4 elements are x, y, w, and h\n",
    "\t\t\tx, y, w, h = netout[int(row)][int(col)][b][:4]\n",
    "\t\t\tx = (col + x) / grid_w # center position, unit: image width\n",
    "\t\t\ty = (row + y) / grid_h # center position, unit: image height\n",
    "\t\t\tw = anchors[2 * b + 0] * np.exp(w) / net_w # unit: image width\n",
    "\t\t\th = anchors[2 * b + 1] * np.exp(h) / net_h # unit: image height\n",
    "\t\t\t# last elements are class probabilities\n",
    "\t\t\tclasses = netout[int(row)][col][b][5:]\n",
    "\t\t\tbox = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
    "\t\t\tboxes.append(box)\n",
    "\treturn boxes\n",
    " \n",
    "def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n",
    "\tnew_w, new_h = net_w, net_h\n",
    "\tfor i in range(len(boxes)):\n",
    "\t\tx_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
    "\t\ty_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
    "\t\tboxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
    "\t\tboxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
    "\t\tboxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
    "\t\tboxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n",
    " \n",
    "def _interval_overlap(interval_a, interval_b):\n",
    "\tx1, x2 = interval_a\n",
    "\tx3, x4 = interval_b\n",
    "\tif x3 < x1:\n",
    "\t\tif x4 < x1:\n",
    "\t\t\treturn 0\n",
    "\t\telse:\n",
    "\t\t\treturn min(x2,x4) - x1\n",
    "\telse:\n",
    "\t\tif x2 < x3:\n",
    "\t\t\t return 0\n",
    "\t\telse:\n",
    "\t\t\treturn min(x2,x4) - x3\n",
    "\n",
    "def box_iou(b1, b2):\n",
    "    '''Return iou tensor\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    b1: tensor, shape=(i1,...,iN, 4), xywh\n",
    "    b2: tensor, shape=(j, 4), xywh\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    iou: tensor, shape=(i1,...,iN, j)\n",
    "\n",
    "    '''\n",
    "\n",
    "    # Expand dim to apply broadcasting.\n",
    "    b1 = K.expand_dims(b1, -2)\n",
    "    b1_xy = b1[..., :2]\n",
    "    b1_wh = b1[..., 2:4]\n",
    "    b1_wh_half = b1_wh/2.\n",
    "    b1_mins = b1_xy - b1_wh_half\n",
    "    b1_maxes = b1_xy + b1_wh_half\n",
    "\n",
    "    # Expand dim to apply broadcasting.\n",
    "    b2 = K.expand_dims(b2, 0)\n",
    "    b2_xy = b2[..., :2]\n",
    "    b2_wh = b2[..., 2:4]\n",
    "    b2_wh_half = b2_wh/2.\n",
    "    b2_mins = b2_xy - b2_wh_half\n",
    "    b2_maxes = b2_xy + b2_wh_half\n",
    "\n",
    "    intersect_mins = K.maximum(b1_mins, b2_mins)\n",
    "    intersect_maxes = K.minimum(b1_maxes, b2_maxes)\n",
    "    intersect_wh = K.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    b1_area = b1_wh[..., 0] * b1_wh[..., 1]\n",
    "    b2_area = b2_wh[..., 0] * b2_wh[..., 1]\n",
    "    iou = intersect_area / (b1_area + b2_area - intersect_area)\n",
    "\n",
    "    return iou\n",
    "\n",
    "        \n",
    "def bbox_iou(box1, box2):\n",
    "\tintersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
    "\tintersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
    "\tintersect = intersect_w * intersect_h\n",
    "\tw1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
    "\tw2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
    "\tunion = w1*h1 + w2*h2 - intersect\n",
    "\treturn float(intersect) / union\n",
    " \n",
    "def do_nms(boxes, nms_thresh):\n",
    "\tif len(boxes) > 0:\n",
    "\t\tnb_class = len(boxes[0].classes)\n",
    "\telse:\n",
    "\t\treturn\n",
    "\tfor c in range(nb_class):\n",
    "\t\tsorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
    "\t\tfor i in range(len(sorted_indices)):\n",
    "\t\t\tindex_i = sorted_indices[i]\n",
    "\t\t\tif boxes[index_i].classes[c] == 0: continue\n",
    "\t\t\tfor j in range(i+1, len(sorted_indices)):\n",
    "\t\t\t\tindex_j = sorted_indices[j]\n",
    "\t\t\t\tif bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
    "\t\t\t\t\tboxes[index_j].classes[c] = 0\n",
    " \n",
    "# load and prepare an image\n",
    "def load_image_pixels(filename, shape):\n",
    "\t# load the image to get its shape\n",
    "\timage = load_img(filename)\n",
    "\twidth, height = image.size\n",
    "\t# load the image with the required size\n",
    "\timage = load_img(filename, target_size=shape)\n",
    "\t# convert to numpy array\n",
    "\timage = img_to_array(image)\n",
    "\t# scale pixel values to [0, 1]\n",
    "\timage = image.astype('float32')\n",
    "\timage /= 255.0\n",
    "\t# add a dimension so that we have one sample\n",
    "\timage = expand_dims(image, 0)\n",
    "\treturn image, width, height\n",
    " \n",
    "# get all of the results above a threshold\n",
    "def get_boxes(boxes, labels, thresh):\n",
    "\tv_boxes, v_labels, v_scores = list(), list(), list()\n",
    "\t# enumerate all boxes\n",
    "\tfor box in boxes:\n",
    "\t\t# enumerate all possible labels\n",
    "\t\tfor i in range(len(labels)):\n",
    "\t\t\t# check if the threshold for this label is high enough\n",
    "\t\t\tif box.classes[i] > thresh:\n",
    "\t\t\t\tv_boxes.append(box)\n",
    "\t\t\t\tv_labels.append(labels[i])\n",
    "\t\t\t\tv_scores.append(box.classes[i]*100)\n",
    "\t\t\t\t# don't break, many labels may trigger for one box\n",
    "\treturn v_boxes, v_labels, v_scores\n",
    " \n",
    "# draw all results\n",
    "def draw_boxes(filename, v_boxes, v_labels, v_scores):\n",
    "\t# load the image\n",
    "\tdata = pyplot.imread(filename)\n",
    "\t# plot the image\n",
    "\tpyplot.imshow(data)\n",
    "\t# get the context for drawing boxes\n",
    "\tax = pyplot.gca()\n",
    "\t# plot each box\n",
    "\tfor i in range(len(v_boxes)):\n",
    "\t\tbox = v_boxes[i]\n",
    "\t\t# get coordinates\n",
    "\t\ty1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n",
    "\t\t# calculate width and height of the box\n",
    "\t\twidth, height = x2 - x1, y2 - y1\n",
    "\t\t# create the shape\n",
    "\t\trect = Rectangle((x1, y1), width, height, fill=False, color='white')\n",
    "\t\t# draw the box\n",
    "\t\tax.add_patch(rect)\n",
    "\t\t# draw text and score in top left corner\n",
    "\t\tlabel = \"%s (%.3f)\" % (v_labels[i], v_scores[i])\n",
    "\t\tpyplot.text(x1, y1, label, color='white')\n",
    "\t# show the plot\n",
    "\tpyplot.show()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 1 160         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 1 64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 1 0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 1 272         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 1 64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 3 1568        leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 3 128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, None, None, 3 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 3 0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, None, 3 1056        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, None, 3 128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, None, None, 3 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, None, 6 6208        leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, None, 6 256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, None, None, 6 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 6 0           leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, None, None, 1 24704       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, None, 1 512         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, None, None, 1 0           leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, None, None, 2 98560       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, None, 2 1024        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, None, None, 2 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, None, None, 2 0           leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, None, None, 5 393728      max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, None, None, 5 2048        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, None, None, 5 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, None, None, 5 0           leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, None, None, 1 1573888     max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, None, None, 1 4096        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, None, None, 2 262400      leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, None, None, 2 1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, None, None, 1 32896       leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, None, None, 1 512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, None, None, 1 0           leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, None, 3 0           leaky_re_lu_7[0][0]              \n",
      "                                                                 up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, None, None, 5 393728      leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, None, None, 2 295168      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, None, None, 5 2048        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, None, None, 2 1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, None, 2 12312       leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, None, None, 2 6168        leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 13, 13, 3, 8) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 26, 26, 3, 8) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "loss (Lambda)                   (None, 1)            0           conv2d_12[0][0]                  \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,115,744\n",
      "Trainable params: 3,109,280\n",
      "Non-trainable params: 6,464\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create custom model with 6 anchors and 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# load yolov3 model\n",
    "# model = load_model(\"real_final_model.h5\")\n",
    "# define the expected input shape for the model\n",
    "annotation_path = '3_CLASS_test.txt'\n",
    "log_dir = 'logs/000/'\n",
    "classes_path = '3_CLASS_test_classes.txt'\n",
    "anchors_path = 'model_data/tiny_yolo_anchors.txt'\n",
    "class_names = get_classes(classes_path)\n",
    "num_classes = len(class_names)\n",
    "anchors = get_anchors(anchors_path)\n",
    "\n",
    "input_shape = (416,416) # multiple of 32, hw\n",
    "\n",
    "# make prediction\n",
    "\n",
    "y_true = [Input(shape=(h//{0:32, 1:16}[l], w//{0:32, 1:16}[l], \\\n",
    "    num_anchors//2, num_classes+5)) for l in range(2)]\n",
    "\n",
    "model_body = make_model( num_anchors//2, num_classes)\n",
    "print('Create custom model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
    "\n",
    "\n",
    "model_loss = Lambda(custom_loss, output_shape=(1,), name='loss',\n",
    "    arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.7})(\n",
    "    [*model_body.output, *y_true])\n",
    "model = Model([model_body.input, *y_true], model_loss)\n",
    "\n",
    "model.load_weights(\"custom_250_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_img(self, image):\n",
    "    image = cv2.imread(image, cv2.IMREAD_COLOR)\n",
    "    original_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    original_image_color = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    r_image, ObjectsList = self.detect_image(original_image_color)\n",
    "    return r_image, ObjectsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_image(image):\n",
    "    if model_image_size != (None, None):\n",
    "        assert self.model_image_size[0]%32 == 0, 'Multiples of 32 required'\n",
    "        assert self.model_image_size[1]%32 == 0, 'Multiples of 32 required'\n",
    "        boxed_image = image_preporcess(np.copy(image), tuple(reversed(self.model_image_size)))\n",
    "        image_data = boxed_image\n",
    "\n",
    "    out_boxes, out_scores, out_classes = self.sess.run(\n",
    "        [self.boxes, self.scores, self.classes],\n",
    "        feed_dict={\n",
    "            self.yolo_model.input: image_data,\n",
    "            self.input_image_shape: [image.shape[0], image.shape[1]],#[image.size[1], image.size[0]],\n",
    "            K.learning_phase(): 0\n",
    "        })\n",
    "\n",
    "    #print('Found {} boxes for {}'.format(len(out_boxes), 'img'))\n",
    "\n",
    "    thickness = (image.shape[0] + image.shape[1]) // 600\n",
    "    fontScale=1\n",
    "    ObjectsList = []\n",
    "\n",
    "    for i, c in reversed(list(enumerate(out_classes))):\n",
    "        predicted_class = self.class_names[c]\n",
    "        box = out_boxes[i]\n",
    "        score = out_scores[i]\n",
    "\n",
    "        label = '{} {:.2f}'.format(predicted_class, score)\n",
    "        #label = '{}'.format(predicted_class)\n",
    "        scores = '{:.2f}'.format(score)\n",
    "\n",
    "        top, left, bottom, right = box\n",
    "        top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "        left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "        bottom = min(image.shape[0], np.floor(bottom + 0.5).astype('int32'))\n",
    "        right = min(image.shape[1], np.floor(right + 0.5).astype('int32'))\n",
    "\n",
    "        mid_h = (bottom-top)/2+top\n",
    "        mid_v = (right-left)/2+left\n",
    "\n",
    "        # put object rectangle\n",
    "        cv2.rectangle(image, (left, top), (right, bottom), self.colors[c], thickness)\n",
    "\n",
    "        # get text size\n",
    "        (test_width, text_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, thickness/self.text_size, 1)\n",
    "\n",
    "        # put text rectangle\n",
    "        cv2.rectangle(image, (left, top), (left + test_width, top - text_height - baseline), self.colors[c], thickness=cv2.FILLED)\n",
    "\n",
    "        # put text above rectangle\n",
    "        cv2.putText(image, label, (left, top-2), cv2.FONT_HERSHEY_SIMPLEX, thickness/self.text_size, (0, 0, 0), 1)\n",
    "\n",
    "        # add everything to list\n",
    "        ObjectsList.append([top, left, bottom, right, mid_v, mid_h, label, scores])\n",
    "\n",
    "    return image, ObjectsList"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
