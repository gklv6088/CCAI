{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import struct\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Input\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from keras.layers import Conv2D, Add, ZeroPadding2D, UpSampling2D, Concatenate, MaxPooling2D\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "import numpy as np\n",
    "import keras as k\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Lambda\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from yolo3.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss, make_model,make_tiny_model\n",
    "from yolo3.utils import get_random_data\n",
    "\n",
    "from functools import wraps\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from yolo3.utils import compose\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(classes_path):\n",
    "    '''loads the classes'''\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names\n",
    "\n",
    "def get_anchors(anchors_path):\n",
    "    '''loads the anchors from a file'''\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "    anchors = [float(x) for x in anchors.split(',')]\n",
    "    return np.array(anchors).reshape(-1, 2)\n",
    "\n",
    "def data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    '''data generator for fit_generator'''\n",
    "    n = len(annotation_lines)\n",
    "    i = 0\n",
    "    while True:\n",
    "        image_data = []\n",
    "        box_data = []\n",
    "        for b in range(batch_size):\n",
    "            if i==0:\n",
    "                np.random.shuffle(annotation_lines)\n",
    "            image, box = get_random_data(annotation_lines[i], input_shape, random=True)\n",
    "            image_data.append(image)\n",
    "            box_data.append(box)\n",
    "            i = (i+1) % n\n",
    "        image_data = np.array(image_data)\n",
    "        box_data = np.array(box_data)\n",
    "        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
    "        yield [image_data, *y_true], np.zeros(batch_size)\n",
    "\n",
    "def data_generator_wrapper(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    n = len(annotation_lines)\n",
    "    if n==0 or batch_size<=0: return None\n",
    "    return data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_path = '3_CLASS_test.txt'\n",
    "log_dir = 'logs/000/'\n",
    "classes_path = '3_CLASS_test_classes.txt'\n",
    "anchors_path = 'model_data/tiny_yolo_anchors.txt'\n",
    "class_names = get_classes(classes_path)\n",
    "num_classes = len(class_names)\n",
    "anchors = get_anchors(anchors_path)\n",
    "num_anchors = len(anchors)\n",
    "\n",
    "input_shape = (416,416) # multiple of 32, hw\n",
    "\n",
    "image_input = Input(shape=(None, None, 3))\n",
    "# model = yolo_body(image_input,num_anchors//3,num_classes)\n",
    "model_body = make_tiny_model(num_classes,num_classes)\n",
    "# model_body.load_weights(\"final_weight_1106.h5\")\n",
    "h, w = input_shape\n",
    "\n",
    "# y_true = [Input(shape=(h//{0:32, 1:16, 2:8}[l], w//{0:32, 1:16, 2:8}[l], \\\n",
    "#     num_anchors//3, num_classes+5)) for l in range(3)]\n",
    "\n",
    "y_true = [Input(shape=(h//{0:32, 1:16}[l], w//{0:32, 1:16}[l], \\\n",
    "    num_anchors//2, num_classes+5)) for l in range(2)]\n",
    "\n",
    "\n",
    "model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})([*model_body.output, *y_true])\n",
    "model = Model([model_body.input, *y_true], model_loss)\n",
    "\n",
    "# model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"yolo_loss_4/add_11:0\", shape=(), dtype=float32)\n",
      "3\n",
      "5202\n",
      "46821\n"
     ]
    }
   ],
   "source": [
    "print(model.output)\n",
    "\n",
    "logging = TensorBoard(log_dir=log_dir)\n",
    "checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n",
    "\n",
    "val_split = 0.1\n",
    "with open(annotation_path) as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "    \n",
    "np.random.shuffle(lines)\n",
    "num_val = int(len(lines)*val_split)\n",
    "num_train = len(lines) - num_val\n",
    "print(num_classes)\n",
    "print(num_val)\n",
    "print(num_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_22 (InputLayer)           (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, None, None, 1 432         input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, None, None, 1 64          conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_56 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling2D) (None, None, None, 1 0           leaky_re_lu_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, None, None, 3 4608        max_pooling2d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, None, None, 3 128         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_57 (LeakyReLU)      (None, None, None, 3 0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling2D) (None, None, None, 3 0           leaky_re_lu_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, None, None, 6 18432       max_pooling2d_32[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, None, None, 6 256         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_58 (LeakyReLU)      (None, None, None, 6 0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling2D) (None, None, None, 6 0           leaky_re_lu_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, None, None, 1 73728       max_pooling2d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, None, None, 1 512         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_59 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling2D) (None, None, None, 1 0           leaky_re_lu_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, None, None, 2 294912      max_pooling2d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, None, None, 2 1024        conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_60 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling2D) (None, None, None, 2 0           leaky_re_lu_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, None, None, 5 1179648     max_pooling2d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, None, None, 5 2048        conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_61 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling2D) (None, None, None, 5 0           leaky_re_lu_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, None, None, 1 4718592     max_pooling2d_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, None, None, 1 4096        conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_62 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, None, None, 2 262144      leaky_re_lu_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, None, None, 2 1024        conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_63 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, None, None, 1 32768       leaky_re_lu_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, None, None, 1 512         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_65 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (None, None, None, 1 0           leaky_re_lu_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, None, None, 3 0           up_sampling2d_6[0][0]            \n",
      "                                                                 leaky_re_lu_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, None, None, 2 884736      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, None, None, 5 2048        conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, None, None, 2 1024        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_64 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_66 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, None, None, 2 12312       leaky_re_lu_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, None, None, 2 6168        leaky_re_lu_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_23 (InputLayer)           (None, 13, 13, 3, 8) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_24 (InputLayer)           (None, 26, 26, 3, 8) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "yolo_loss (Lambda)              (None, 1)            0           conv2d_75[0][0]                  \n",
      "                                                                 conv2d_78[0][0]                  \n",
      "                                                                 input_23[0][0]                   \n",
      "                                                                 input_24[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 8,680,864\n",
      "Trainable params: 8,674,496\n",
      "Non-trainable params: 6,368\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46821 samples, val on 5202 samples, with batch size 8.\n",
      "Epoch 1/35\n",
      "5852/5852 [==============================] - 3258s 557ms/step - loss: 54.6710 - val_loss: 22.4187\n",
      "Epoch 2/35\n",
      "5852/5852 [==============================] - 3273s 559ms/step - loss: 19.5439 - val_loss: 18.6605\n",
      "Epoch 3/35\n",
      "5852/5852 [==============================] - 3186s 544ms/step - loss: 17.7765 - val_loss: 17.5305\n",
      "Epoch 4/35\n",
      "5852/5852 [==============================] - 3206s 548ms/step - loss: 16.9458 - val_loss: 16.7414\n",
      "Epoch 5/35\n",
      "5852/5852 [==============================] - 3214s 549ms/step - loss: 16.4148 - val_loss: 16.3985\n",
      "Epoch 6/35\n",
      "5852/5852 [==============================] - 3194s 546ms/step - loss: 16.0496 - val_loss: 16.6905\n",
      "Epoch 7/35\n",
      "5852/5852 [==============================] - 3201s 547ms/step - loss: 15.7049 - val_loss: 15.6234\n",
      "Epoch 8/35\n",
      "5852/5852 [==============================] - 3187s 545ms/step - loss: 15.5766 - val_loss: 15.6916\n",
      "Epoch 9/35\n",
      "5852/5852 [==============================] - 3191s 545ms/step - loss: 15.3103 - val_loss: 15.5861\n",
      "Epoch 10/35\n",
      "5852/5852 [==============================] - 3189s 545ms/step - loss: 15.1948 - val_loss: 15.3714\n",
      "Epoch 11/35\n",
      "5852/5852 [==============================] - 3191s 545ms/step - loss: 15.0898 - val_loss: 15.1215\n",
      "Epoch 12/35\n",
      "5852/5852 [==============================] - 3183s 544ms/step - loss: 14.8617 - val_loss: 15.1142\n",
      "Epoch 13/35\n",
      "5852/5852 [==============================] - 3193s 546ms/step - loss: 14.8628 - val_loss: 14.6854\n",
      "Epoch 14/35\n",
      "5852/5852 [==============================] - 3195s 546ms/step - loss: 14.7262 - val_loss: 15.1665\n",
      "Epoch 15/35\n",
      "5852/5852 [==============================] - 3189s 545ms/step - loss: 14.6557 - val_loss: 14.8136\n",
      "Epoch 16/35\n",
      "5852/5852 [==============================] - 3184s 544ms/step - loss: 14.5410 - val_loss: 14.7477\n",
      "Epoch 17/35\n",
      "5852/5852 [==============================] - 3194s 546ms/step - loss: 14.4858 - val_loss: 14.6342\n",
      "Epoch 18/35\n",
      "5852/5852 [==============================] - 3185s 544ms/step - loss: 14.4627 - val_loss: 15.1191\n",
      "Epoch 19/35\n",
      "5852/5852 [==============================] - 3190s 545ms/step - loss: 14.4075 - val_loss: 14.7355\n",
      "Epoch 20/35\n",
      "5852/5852 [==============================] - 3184s 544ms/step - loss: 14.3785 - val_loss: 14.6334\n",
      "Epoch 21/35\n",
      "5852/5852 [==============================] - 3191s 545ms/step - loss: 14.2621 - val_loss: 14.5412\n",
      "Epoch 22/35\n",
      "5852/5852 [==============================] - 3193s 546ms/step - loss: 14.2024 - val_loss: 14.3679\n",
      "Epoch 23/35\n",
      "5852/5852 [==============================] - 3190s 545ms/step - loss: 14.2273 - val_loss: 14.3079\n",
      "Epoch 24/35\n",
      "5852/5852 [==============================] - 3200s 547ms/step - loss: 14.1619 - val_loss: 14.2670\n",
      "Epoch 25/35\n",
      "5852/5852 [==============================] - 3189s 545ms/step - loss: 14.0455 - val_loss: 14.5561\n",
      "Epoch 26/35\n",
      "5852/5852 [==============================] - 3196s 546ms/step - loss: 14.0750 - val_loss: 14.3008\n",
      "Epoch 27/35\n",
      "5852/5852 [==============================] - 3189s 545ms/step - loss: 14.0037 - val_loss: 14.0176\n",
      "Epoch 28/35\n",
      "5852/5852 [==============================] - 3187s 545ms/step - loss: 13.9199 - val_loss: 14.4883\n",
      "Epoch 29/35\n",
      "5852/5852 [==============================] - 3194s 546ms/step - loss: 13.9314 - val_loss: 14.3543\n",
      "Epoch 30/35\n",
      "5852/5852 [==============================] - 3187s 545ms/step - loss: 13.8911 - val_loss: 14.0712\n",
      "Epoch 31/35\n",
      "5852/5852 [==============================] - 3184s 544ms/step - loss: 13.8906 - val_loss: 14.3909\n",
      "Epoch 32/35\n",
      "5852/5852 [==============================] - 3187s 545ms/step - loss: 13.8400 - val_loss: 14.2163\n",
      "Epoch 33/35\n",
      "5852/5852 [==============================] - 3192s 545ms/step - loss: 13.7719 - val_loss: 14.0815\n",
      "Epoch 34/35\n",
      "5852/5852 [==============================] - 3194s 546ms/step - loss: 13.8267 - val_loss: 14.0487\n",
      "Epoch 35/35\n",
      "5852/5852 [==============================] - 3188s 545ms/step - loss: 13.7579 - val_loss: 13.8416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe85143cbe0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(lr=1e-4), loss={'yolo_loss': lambda y_true, y_pred: y_pred})\n",
    "    \n",
    "batch_size = 8\n",
    "print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
    "        steps_per_epoch=max(1, num_train//batch_size),\n",
    "        validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
    "        validation_steps=max(1, num_val//batch_size),\n",
    "        epochs=35,\n",
    "        callbacks=[logging, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"highway_tiny_weight.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
